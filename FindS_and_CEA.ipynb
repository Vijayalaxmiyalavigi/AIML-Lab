{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Find-S Algorithm Implementation"
      ],
      "metadata": {
        "id": "BUBquVcdskrs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km-twC86VsjR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zd6PfxlDr5DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L27EXOEhCNgj",
        "outputId": "3fdd50e2-3d10-45dc-da24-5c08bfb999fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSQBIvAzDYko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = []\n",
        "def read_data():\n",
        "  with open(\"/content/drive/MyDrive/Dataset/tennis.csv\", 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile,delimiter=',')\n",
        "    traindata = list(reader)\n",
        "\n",
        "  return(traindata)"
      ],
      "metadata": {
        "id": "p4y5dqbcWYru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = read_data()\n"
      ],
      "metadata": {
        "id": "QxoxouxO475f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(traindata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z4hNTyV5Ct5",
        "outputId": "57eaaaf1-b62e-4ed7-c081-4394697fc7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['outlook', 'temp', 'humidity', 'wind', 'play'], ['Sunny', 'Hot', 'High', 'Weak', 'No'], ['Sunny', 'Hot', 'High', 'Strong', 'No'], ['Overcast', 'Hot', 'High', 'Weak', 'Yes'], ['Rain', 'Mild', 'High', 'Weak', 'Yes'], ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'], ['Rain', 'Cool', 'Normal', 'Strong', 'No'], ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'], ['Sunny', 'Mild', 'High', 'Weak', 'No'], ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'], ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'], ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'], ['Overcast', 'Mild', 'High', 'Strong', 'Yes'], ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'], ['Rain', 'Mild', 'High', 'Strong', 'No']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_attributes = 6\n",
        "hypothesis = []\n",
        "print(\"\\n The initial value of hypothesis: \")\n",
        "hypothesis = ['0'] * num_attributes\n",
        "print(hypothesis)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48EOMlSOXFcm",
        "outputId": "97e41465-4ab5-4b4c-c535-59615fa9bed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The initial value of hypothesis: \n",
            "['0', '0', '0', '0', '0', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find S Function\n",
        "def FindS():\n",
        "  dataarr = read_data()\n",
        "\n",
        "  rows = len(dataarr)\n",
        "  columns = 5\n",
        "  rows = len(dataarr)\n",
        "  print(dataarr[0])\n",
        "\n",
        "  for x in range(1,rows):\n",
        "    currentrow = dataarr[x]\n",
        "    print(\"current row is\",currentrow)\n",
        "    print(currentrow[columns-1])\n",
        "    if currentrow[columns-1]==\"Yes\":\n",
        "           for y in range(columns):\n",
        "                if hypothesis[y]==currentrow[y]:\n",
        "                  pass\n",
        "                elif hypothesis[y]=='0':\n",
        "                  hypothesis[y]= currentrow[y]\n",
        "                else:\n",
        "                  hypothesis[y] = '?'\n",
        "\n",
        "           print(hypothesis)\n",
        "  print(\"Final hypothesis is\\n\")\n",
        "  for i in range(0,(columns-1)):\n",
        "    print(hypothesis[i],end = ' ')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRUPiguMYP06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FindS()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqM_599MDodu",
        "outputId": "a1629143-86d4-4003-aa2d-de622b2a4c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['outlook', 'temp', 'humidity', 'wind', 'play']\n",
            "current row is ['Sunny', 'Hot', 'High', 'Strong', 'No']\n",
            "No\n",
            "['Sunny', 'Hot', 'High', 'Weak', 'No']\n",
            "current row is ['Overcast', 'Hot', 'High', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', 'Hot', 'High', 'Weak', '?']\n",
            "current row is ['Rain', 'Mild', 'High', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', '?', 'High', 'Weak', '?']\n",
            "current row is ['Rain', 'Cool', 'Normal', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', 'Weak', '?']\n",
            "current row is ['Rain', 'Cool', 'Normal', 'Strong', 'No']\n",
            "No\n",
            "['?', '?', '?', 'Weak', '?']\n",
            "current row is ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Sunny', 'Mild', 'High', 'Weak', 'No']\n",
            "No\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Rain', 'Mild', 'Normal', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Overcast', 'Mild', 'High', 'Strong', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes']\n",
            "Yes\n",
            "['?', '?', '?', '?', '?']\n",
            "current row is ['Rain', 'Mild', 'High', 'Strong', 'No']\n",
            "No\n",
            "['?', '?', '?', '?', '?']\n",
            "Final hypothesis is\n",
            "\n",
            "? ? ? ? "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidate Elimination Algorithm Implementation"
      ],
      "metadata": {
        "id": "pyrEdWaTMBCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraires'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "id": "xEsm3T-xY8MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to read data from a CSV file\n",
        "def read_data():\n",
        "  with open(\"/content/ENJOYSPORT.csv\") as csvfile:\n",
        "\n",
        "    reader = csv.reader(csvfile)\n",
        "    # Convert the data read from the CSV file into a DataFrame using pandas\n",
        "    df = pd.DataFrame(reader)\n",
        "    # Return the resulting DataFrame containing the CSV data\n",
        "  return(df)\n"
      ],
      "metadata": {
        "id": "mbqZXnR5NgOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = read_data()\n",
        "print(traindata)"
      ],
      "metadata": {
        "id": "NizG5PvSTkY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "  with open(\"/content/colors.csv\") as csvfile:\n",
        "\n",
        "    reader = csv.reader(csvfile)\n",
        "    df = pd.DataFrame(reader)\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "lyH-F_8Hl20S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "  with open(\"/content/drive/MyDrive/Dataset/ds3.csv\") as csvfile:\n",
        "\n",
        "    reader = csv.reader(csvfile)\n",
        "    df = pd.DataFrame(reader)\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "KDyPFKFx1By1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ikgRDNkzu7oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Dataset**"
      ],
      "metadata": {
        "id": "nDAaaTu1dkDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the domain of the index columnfrom the traindata -df\n",
        "def get_domains(index):\n",
        "    domain = []\n",
        "    domain = traindata[index].unique()\n",
        "    return(domain)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPwR5XDKYa3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvBnf34cw22X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 'g_0' function, which initializes the general hypothesis to '?'\n",
        "def g_0(ncols):\n",
        "   # Create a list containing '?' for each column (attribute)\n",
        "    return [\"?\",]*ncols\n",
        "# Define the 's_0' function, which initializes the specific hypothesis to '0'\n",
        "def s_0(ncols):\n",
        "  # Create a list containing '0' for each column (attribute)\n",
        "    return ['0',]*ncols\n"
      ],
      "metadata": {
        "id": "0rhR1UF52V7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define a function to check if all elements in the list 'G' are equal to '?'\n",
        "def check_g(G):\n",
        "  # Convert the list 'G' into a NumPy array for element-wise comparison\n",
        "  c = np.array(G)\n",
        "  # Check if all elements in the NumPy array are equal to '?'\n",
        "  if((c=='?').all()):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "_edRpGfGAgh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generalize the specific hypothesis 'S' based on a 'currentrow'\n",
        "def Generalize_S(currentrow,S):\n",
        "   # Iterate through the elements of 'S' and 'currentrow'\n",
        "  for x in range(0,len(S)):\n",
        "     # If the corresponding elements are the same, do nothing (pass)\n",
        "    if(S[x]==currentrow[x]):\n",
        "         pass\n",
        "    # If 'S' has '0' (indicating a default assumption), update 'S' with the value from 'currentrow'\n",
        "    elif S[x]=='0':\n",
        "         S[x]= currentrow[x]\n",
        "    # If 'S' has a different value, set it to '?', indicating uncertainty\n",
        "    else:\n",
        "         S[x] = '?'\n",
        "  # Return the updated 'S'\n",
        "  return(S)\n"
      ],
      "metadata": {
        "id": "bUKiDkxI0C22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to remove elements from the list 'G' based on a 'currentrow'\n",
        "def Remove_G(currentrow,G):\n",
        "  # Initialize an empty list to store eliminated elements\n",
        "   G_eliminate = []\n",
        "   current_h = []\n",
        "   # Iterate through the elements in 'G'\n",
        "   for x in range(0,len(G)):\n",
        "      current_h= G[x]\n",
        "      # Create an iterator that pairs the elements of 'currentrow' and 'current_h'\n",
        "      zip_obj=zip(currentrow,current_h)\n",
        "      # Iterate through the pairs\n",
        "      for a,b in zip_obj:\n",
        "        # If 'a' and 'b' are the same or 'b' is '?', do nothing (pass)\n",
        "        if(a==b or b =='?'):\n",
        "           pass\n",
        "        else:\n",
        "          # If 'a' and 'b' are different, add 'current_h' to the elimination list\n",
        "           G_eliminate.extend([current_h])\n",
        "\n",
        "   #print(G_eliminate)\n",
        "   # Remove elements from 'G' that are present in the elimination list\n",
        "   G= [value  for value in G if value not in G_eliminate]\n",
        "   return(G)"
      ],
      "metadata": {
        "id": "_dTBfvNv0nM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method Specilialises G initially when G=['?..]\n",
        "# Define a function to specialize the general hypotheses 'G' based on a 'currentrow'\n",
        "def add_hypothesis(currentrow,G):\n",
        "  # Initialize the index and create a new hypothesis 'h_new' filled with '?'\n",
        "  index=0\n",
        "  h_new = ['?'] * ncols\n",
        "  # Iterate through the elements in 'currentrow' (except the last one because last one is the target column)\n",
        "  for x in range(0,len(currentrow)-1):\n",
        "     domain = get_domains(index)          # Unique Values of the Column.\n",
        "      # Iterate through the domain values of the column\n",
        "     for y  in range(0,len(domain)):\n",
        "      # Check if the current attribute value 'currentrow[x]' matches a value in the domain 'domain[y]'\n",
        "       if(currentrow[x]==domain[y]):\n",
        "        # If they match, do nothing (pass)\n",
        "        pass\n",
        "       else:\n",
        "        # Update 'h_new' with the new value, add it to 'G', and reset 'h_new'\n",
        "        h_new[index]=domain[y]\n",
        "        G.append(h_new)\n",
        "        h_new = ['?'] * ncols\n",
        "     index=index+1\n",
        "\n",
        "  return(G)\n"
      ],
      "metadata": {
        "id": "ZPAhKFStDimr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Specialize_G(current_h,currentrow,x,G,G_new):\n",
        "   h_new = current_h\n",
        "   print(\"current hypo is \", current_h)\n",
        "   G_new=[]\n",
        "   h_old = h_new.copy()\n",
        "   #print(\"Current hypothesis is\",h_new)\n",
        "   qindices =  [idx for idx, value in enumerate(h_new) if value == '?']\n",
        "\n",
        "   for qindex in qindices:\n",
        "\n",
        "        domain = get_domains(qindex)         # get the domain for specific column\n",
        "        filtered_domain =[value for value in domain if value != currentrow[qindex]] # Filter the domain to contain opposite value\n",
        "        for ele in filtered_domain:\n",
        "                               # loop to replace each qp indexed by qindex with ele from domain.\n",
        "           h_new[qindex] = ele\n",
        "           G_new.extend([h_new])\n",
        "\n",
        "           h_new = h_old.copy()\n",
        "\n",
        "   return(G_new)"
      ],
      "metadata": {
        "id": "Xt4n4PCNECCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to check the consistency of a hypothesis 'hypothesis' with a dataset up to a specified 'row'\n",
        "def Check_H_For_Consistant(hypothesis,x,row):\n",
        "  # Iterate through the rows in the dataset up to 'row'\n",
        "  for i in range(0,row+1):\n",
        "     # Extract the current row from the dataset and convert it to a list\n",
        "     trainrow = list(traindata.iloc[i])\n",
        "     count_yes=0\n",
        "     count_no=0\n",
        "     # Create pairs of attributes from the 'hypothesis' and the current 'trainrow'\n",
        "     zip_obj=zip(hypothesis,trainrow[:-1])\n",
        "     new_list = list(zip_obj)\n",
        "     # Check if the class in 'trainrow' is 'yes'\n",
        "     if(trainrow[-1].lower()=='yes'):\n",
        "       for a,b in new_list:\n",
        "          #print(a,b)\n",
        "          # If the attribute in 'hypothesis' is '?' or matches the current 'trainrow', increment 'count_yes'\n",
        "          if(a==\"?\" or a==b):\n",
        "              count_yes+=1\n",
        "              # If 'count_yes' equals the number of attributes in 'hypothesis' and this is the last row, return True\n",
        "              if(count_yes==len(new_list) and i==row):\n",
        "                  #print(\"Hypotheis is consistant\", hypothesis)\n",
        "                  return True\n",
        "              continue\n",
        "          # If any attribute in 'hypothesis' doesn't match the 'trainrow', return False\n",
        "          if(a!=b):\n",
        "              return False\n",
        "     # Check if the class in 'trainrow' is 'no'\n",
        "     if(trainrow[-1].lower()=='no'):\n",
        "         # Count the number of non-'?' attributes in 'hypothesis'\n",
        "         h_len=[j for i,j in enumerate(hypothesis) if j!='?']\n",
        "         # If there is only one non-'?' attribute in 'hypothesis', check for consistency and only one value should be checked\n",
        "         if(len(h_len)==1):\n",
        "           for a,b in new_list:\n",
        "              count_no+=1\n",
        "              # If any attribute in 'hypothesis' matches the 'trainrow', return False\n",
        "              if(a==b):\n",
        "                return False\n",
        "              # If 'count_no' equals the number of attributes in 'hypothesis' and this is the last row, return True\n",
        "              elif(count_no==len(new_list) and i==row):\n",
        "                return True\n",
        "         # If there are multiple non-'?' attributes in 'hypothesis', check for consistency\n",
        "         if(len(h_len) > 1):\n",
        "          for a,b in new_list:\n",
        "            count_no+=1\n",
        "            # If any attribute in 'hypothesis' doesn't match the 'trainrow' and this is the last row, return True\n",
        "            if(a!=b and a!='?' and i==row):\n",
        "               return True\n",
        "            # If 'count_no' equals the number of attributes in 'hypothesis' and this is the last row, return False\n",
        "            elif(count_no==len(new_list) and i==row):\n",
        "               return False\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ahGotFdVu3hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ***** Start of the Program ********\n",
        "# Define a function to implement the Candidate Elimination Algorithm\n",
        "def candidate_elimination():\n",
        "  # Initialize specific and general hypotheses\n",
        "  G = [g_0(ncols)] # G is always a 2D array because it will be list of hypotheses\n",
        "  S = s_0(ncols)\n",
        "  print(\"S=\", S)\n",
        "  print(\"G=\", G)\n",
        "  # Iterate through the training data\n",
        "  for row in range(0,len(traindata)):\n",
        "    currentrow = list(traindata.iloc[row])\n",
        "    print(\"The current row is\\n\")\n",
        "    print(currentrow)\n",
        "    # If the class is 'yes', update i.e Generalize S and remove Inconsistent hypotheses from G\n",
        "    if(currentrow[-1].lower()=='yes'):\n",
        "      S=Generalize_S(currentrow,S)\n",
        "      G=Remove_G(currentrow, G)\n",
        "      print(\"S =\" ,S)\n",
        "      print(\"G =\", G)\n",
        "      # If G initially contains only [\"?\"....], add new hypotheses\n",
        "    elif len([G])==1 and (check_g(G)== True):  # Intially when G is having only [\"?\"....] G Boundry not moved\n",
        "      G.clear()\n",
        "      G_eliminate =[]\n",
        "      G = add_hypothesis(currentrow,G)\n",
        "      print(\"The Hypothesis added are = \",G)\n",
        "      for x in range(0,len(G)):\n",
        "          consistant = Check_H_For_Consistant(G[x],x,row)\n",
        "          if(consistant==True):\n",
        "             pass\n",
        "          else:\n",
        "            G_eliminate.extend([G[x]])\n",
        "      G=[value  for value in G if value not in G_eliminate]\n",
        "      print(\"S = \", S)\n",
        "      print(\"G = \",G)\n",
        "      # Otherwise, G already contains hypotheses, so update it\n",
        "      # G already has some Hypothesis\n",
        "    else:\n",
        "        G_new=[] # Create a new list to store updated hypotheses\n",
        "        nrows = len(G)\n",
        "        consistant=False\n",
        "         # Iterate through the current hypotheses in G\n",
        "        for x in range(0,nrows):\n",
        "          consistant = Check_H_For_Consistant(G[x],x,row)\n",
        "          if(consistant==True):\n",
        "             #print(\"Hypothesis is consistant to all examples \",G[x])\n",
        "             # Hypothesis is consistent with all examples\n",
        "             G_new.append(G[x])\n",
        "             pass\n",
        "          else:\n",
        "            # Hypothesis is not consistent with all examples, specialize it\n",
        "             #print(\"Hypothesis is NOT consistant to all examples \",G[x])\n",
        "             G_new.extend(Specialize_G(G[x],currentrow,x,G,G_new))\n",
        "        G=G_new.copy()\n",
        "\n",
        "        print(\"S = \", S)\n",
        "        print(\"G= \", G)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YRwoHT2mdopu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execution Begins Here\n",
        "traindata = read_data()\n",
        "traindata = traindata.iloc[1:]\n",
        "print(traindata)\n",
        "ncols = len(traindata.columns)\n",
        "ncols = ncols-1             # To exclude last column(target)\n",
        "candidate_elimination()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxiP0emjwm2I",
        "outputId": "2c3192aa-3cea-4296-f2e5-ff93c6605dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0     1       2       3     4       5    6\n",
            "1  Sunny  Warm  Normal  Strong  Warm    Same  Yes\n",
            "2  Sunny  Warm    High  Strong  Warm    Same  Yes\n",
            "3  Rainy  Cold    High  Strong  Warm  Change   No\n",
            "4  Sunny  Warm    High  Strong  Cool  Change  Yes\n",
            "S= ['0', '0', '0', '0', '0', '0']\n",
            "G= [['?', '?', '?', '?', '?', '?']]\n",
            "The current row is\n",
            "\n",
            "['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n",
            "S = ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same']\n",
            "G = [['?', '?', '?', '?', '?', '?']]\n",
            "The current row is\n",
            "\n",
            "['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n",
            "S = ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
            "G = [['?', '?', '?', '?', '?', '?']]\n",
            "The current row is\n",
            "\n",
            "['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n",
            "The Hypothesis added are =  [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', 'Normal', '?', '?', '?'], ['?', '?', '?', '?', 'Cool', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
            "S =  ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
            "G =  [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
            "The current row is\n",
            "\n",
            "['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n",
            "S = ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
            "G = [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPFg-jku2TMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IDS Decision Tree Algorithm**"
      ],
      "metadata": {
        "id": "d38nxtAhU20j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UwJDmtAtFaj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ARBuDyxPB055"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fLA13DXc_uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yges6gzoc_q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dwpR3N5iB9GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NpWsBauEd1-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOYo-pQzjf1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}